{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "from metrics import nse, kge\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import json\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '/home/bdemiray/storage/Benchmark/Data/'\n",
    "RIDGE_PATH = \"/home/bdemiray/storage/Benchmark/Results/SingleStation/Ridge\"\n",
    "LASSO_PATH = \"/home/bdemiray/storage/Benchmark/Results/SingleStation/Lasso\"\n",
    "RIDGE_SUMMARY = \"ridgeSummary.json\"\n",
    "LASSO_SUMMARY = \"lassoSummary.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSummaryFile(filename):\n",
    "    \"\"\"\n",
    "    Create a summary file for the results of each gauge\n",
    "        \n",
    "    Parameters:\n",
    "        filename, str:\n",
    "            filename(path) of the summary file\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    Results = {}\n",
    "    Results[\"Train\"] = {}\n",
    "    Results[\"Test\"] = {}\n",
    "    Results[\"Train\"][\"NSE\"] = {}\n",
    "    Results[\"Train\"][\"KGE\"] = {}\n",
    "    Results[\"Test\"][\"NSE\"] = {}\n",
    "    Results[\"Test\"][\"KGE\"] = {}\n",
    "    Results[\"Train\"][\"NSE\"][\"max\"] = {}\n",
    "    Results[\"Train\"][\"NSE\"][\"min\"] = {}\n",
    "    Results[\"Train\"][\"NSE\"][\"median\"] = {}\n",
    "    Results[\"Train\"][\"NSE\"][\"mean\"] = {}\n",
    "    Results[\"Train\"][\"KGE\"][\"max\"] = {}\n",
    "    Results[\"Train\"][\"KGE\"][\"min\"] = {}\n",
    "    Results[\"Train\"][\"KGE\"][\"median\"] = {}\n",
    "    Results[\"Train\"][\"KGE\"][\"mean\"] = {}\n",
    "    Results[\"Test\"][\"NSE\"][\"max\"] = {}\n",
    "    Results[\"Test\"][\"NSE\"][\"min\"] = {}\n",
    "    Results[\"Test\"][\"NSE\"][\"median\"] = {}\n",
    "    Results[\"Test\"][\"NSE\"][\"mean\"] = {}\n",
    "    Results[\"Test\"][\"KGE\"][\"max\"] = {}\n",
    "    Results[\"Test\"][\"KGE\"][\"min\"] = {}\n",
    "    Results[\"Test\"][\"KGE\"][\"median\"] = {}\n",
    "    Results[\"Test\"][\"KGE\"][\"mean\"] = {}\n",
    "    \n",
    "    with open(filename, \"w\") as outfile:\n",
    "        json.dump(Results, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateJSON(station_id, NSE_train, NSE_test, KGE_train, KGE_test, jsonFilePath):\n",
    "    \"\"\"\n",
    "    Updates the summary file with results of a gauge\n",
    "    \n",
    "    Parameters:\n",
    "        station_id, int:\n",
    "            id of the gauge which results will be added to summary file\n",
    "        NSE_train, list:\n",
    "            NSE scores of train set\n",
    "        NSE_test, list:\n",
    "            NSE scores of test set\n",
    "        KGE_train, list:\n",
    "            KGE scores of train set\n",
    "        KGE_test, list:\n",
    "            KGE scores of test set\n",
    "        jsonFilePath, str:\n",
    "            path of the updated summary file\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    nse_train_max = np.max(NSE_train)\n",
    "    nse_train_min = np.min(NSE_train)\n",
    "    nse_train_median = np.median(NSE_train)\n",
    "    nse_train_mean = np.mean(NSE_train)\n",
    "    \n",
    "    nse_test_max = np.max(NSE_test)\n",
    "    nse_test_min = np.min(NSE_test)\n",
    "    nse_test_median = np.median(NSE_test)\n",
    "    nse_test_mean = np.mean(NSE_test)\n",
    "    \n",
    "    kge_train_max = np.max(KGE_train)\n",
    "    kge_train_min = np.min(KGE_train)\n",
    "    kge_train_median = np.median(KGE_train)\n",
    "    kge_train_mean = np.mean(KGE_train)\n",
    "    \n",
    "    kge_test_max = np.max(KGE_test)\n",
    "    kge_test_min = np.min(KGE_test)\n",
    "    kge_test_median = np.median(KGE_test)\n",
    "    kge_test_mean = np.mean(KGE_test)\n",
    "    \n",
    "    with open(jsonFilePath, \"r\") as jsonFile:\n",
    "        Results = json.load(jsonFile)\n",
    "    \n",
    "    Results[\"Train\"][\"NSE\"][\"max\"][station_id] = nse_train_max\n",
    "    Results[\"Train\"][\"NSE\"][\"min\"][station_id] = nse_train_min\n",
    "    Results[\"Train\"][\"NSE\"][\"median\"][station_id] = nse_train_median\n",
    "    Results[\"Train\"][\"NSE\"][\"mean\"][station_id] = nse_train_mean\n",
    "    \n",
    "    Results[\"Train\"][\"KGE\"][\"max\"][station_id] = kge_train_max\n",
    "    Results[\"Train\"][\"KGE\"][\"min\"][station_id] = kge_train_min\n",
    "    Results[\"Train\"][\"KGE\"][\"median\"][station_id] = kge_train_median\n",
    "    Results[\"Train\"][\"KGE\"][\"mean\"][station_id] = kge_train_mean\n",
    "    \n",
    "    Results[\"Test\"][\"NSE\"][\"max\"][station_id] = nse_test_max\n",
    "    Results[\"Test\"][\"NSE\"][\"min\"][station_id] = nse_test_min\n",
    "    Results[\"Test\"][\"NSE\"][\"median\"][station_id] = nse_test_median\n",
    "    Results[\"Test\"][\"NSE\"][\"mean\"][station_id] = nse_test_mean\n",
    "    \n",
    "    Results[\"Test\"][\"KGE\"][\"max\"][station_id] = kge_test_max\n",
    "    Results[\"Test\"][\"KGE\"][\"min\"][station_id] = kge_test_min\n",
    "    Results[\"Test\"][\"KGE\"][\"median\"][station_id] = kge_test_median\n",
    "    Results[\"Test\"][\"KGE\"][\"mean\"][station_id] = kge_test_mean\n",
    "    \n",
    "    with open(jsonFilePath, \"w\") as jsonFile:\n",
    "        json.dump(Results, jsonFile)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ridge_main(station_id, DATASET_PATH, RESULT_PATH=None, summaryFile):\n",
    "    \"\"\"\n",
    "    Main function to get results of Seq2Seq model for given gauge\n",
    "    \n",
    "    Parameters:\n",
    "        station_id, str:\n",
    "            id of gauge which model will use its training and test data\n",
    "        RESULT_PATH, str:\n",
    "            directory to store the results\n",
    "        DATASET_PATH, str:\n",
    "            path to dataset which contains test and training data for each gauge as csv    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    train_x = pd.read_csv(DATASET_PATH+str(station_id)+'_train_x.csv',index_col='datetime')\n",
    "    train_y = pd.read_csv(DATASET_PATH+str(station_id)+'_train_y.csv',index_col='datetime')\n",
    "    test_x = pd.read_csv(DATASET_PATH+str(station_id)+'_test_x.csv',index_col='datetime')\n",
    "    test_y = pd.read_csv(DATASET_PATH+str(station_id)+'_test_y.csv',index_col='datetime')\n",
    "    \n",
    "    train_x = train_x.values[:,:-7]\n",
    "    test_x = test_x.values[:,:-7]\n",
    "\n",
    "    scaler_x = MinMaxScaler()\n",
    "    scaler_y = MinMaxScaler()\n",
    "    scaler_x.fit(train_x)\n",
    "    scaler_y.fit(train_y)\n",
    "    \n",
    "    train_x_scaled = scaler_x.transform(train_x)\n",
    "    test_x_scaled = scaler_x.transform(test_x)\n",
    "    train_y_scaled = scaler_y.transform(train_y)\n",
    "    \n",
    "    \n",
    "    clf = linear_model.Ridge()\n",
    "\n",
    "    clf.fit(train_x_scaled, train_y_scaled)\n",
    "    \n",
    "    y_train_pred = clf.predict(train_x_scaled)\n",
    "    y_test_pred = clf.predict(test_x_scaled)\n",
    "    \n",
    "    y_train_pred = scaler_y.inverse_transform(y_train_pred)\n",
    "    y_test_pred = scaler_y.inverse_transform(y_test_pred)\n",
    "    \n",
    "    NSEs_train = []\n",
    "    NSEs_test = []\n",
    "    KGEs_train = []\n",
    "    KGEs_test = []\n",
    "    \n",
    "    for i in range(120):\n",
    "        NSEs_train.append(nse(train_y.values[:, i], y_train_pred[:, i]))\n",
    "        NSEs_test.append(nse(test_y.values[:, i], y_test_pred[:, i]))\n",
    "        KGEs_train.append(kge(train_y.values[:, i], y_train_pred[:, i]))\n",
    "        KGEs_test.append(kge(test_y.values[:, i], y_test_pred[:, i]))\n",
    "    \n",
    "    updateJSON(station_id, NSEs_train, NSEs_test, KGEs_train, KGEs_test, summaryFile)\n",
    "    \n",
    "    KGE_train = pd.DataFrame(KGEs_train)\n",
    "    KGE_test = pd.DataFrame(KGEs_test)\n",
    "    KGE_train.columns = [\"KGEsTrain\"]\n",
    "    KGE_test.columns = [\"KGEsTest\"]\n",
    "    NSE_train = pd.DataFrame(NSEs_train)\n",
    "    NSE_test = pd.DataFrame(NSEs_test)\n",
    "    NSE_train.columns = [\"NSEsTrain\"]\n",
    "    NSE_test.columns = [\"NSEsTest\"]\n",
    "    \n",
    "    \n",
    "    combined = pd.concat([NSE_train, NSE_test, KGE_train, KGE_test], axis=1)\n",
    "    combined.to_csv(\"%s/%s.csv\" % (RESULT_PATH, str(station_id)), index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createSummaryFile(summary_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = originalData # unzip the files in originalData folder and gave as dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = os.listdir(data)\n",
    "sensors = [i.split(\"_\")[0] for i in l]\n",
    "sensors = list(set(sensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sensor in sensors:\n",
    "    Ridge_main(sensor, DATA, RESULT_PATH, summary_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
